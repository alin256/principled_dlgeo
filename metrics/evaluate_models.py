import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from utils.utils import generate_noise
from metrics.python_metrics import compute_mean_facies_proportions, get_connected_components_stats_per_facies
import scipy


def compare_3d_models_morpho(real_data, models, models_names, facies_ids=None, batch_size=750):
    """
    Compare models using morphological properties using gstlearn. Morphological properties are facies proportions
    and the distribution (violin plot) of connected components sizes.
    Args:
        real_data: (ndarray) The real dataset of images
        models: (list(keras.models.Model)) list of models coded in Tensorrflow/Keras
        models_names: (list(string)) a list of models names for the models (must be same size as array 'models')
        facies_ids: (list(string)) a list of facies IDs names
        batch_size: number of images generated by each models (there is no batch size for real data, morph. prop. will
                    be computed on the whole dataset)
    Returns:
        None
    """
    sns.set(font_scale=1.5)
    slice_size = (real_data.shape[1], real_data.shape[2], real_data.shape[3])
    noise_shape = (2, 4, 8, 1)
    nb_facies = 4
    real_dataset_size = real_data.shape[0]

    # Array containing unique facies ID
    unique_facies = np.array(list(range(0, nb_facies)))

    if facies_ids is None:
        facies_ids = unique_facies

    # Compute it for real data
    real_data = real_data.astype(np.float64)
    real_mean_proportion = compute_mean_facies_proportions(real_data, slice_size, real_dataset_size, 2, unique_facies)
    _, real_weighted_conn_size, real_conn_size = get_connected_components_stats_per_facies(real_data, slice_size,
                                                                     real_dataset_size, 2, unique_facies)

    # Create the dictionaries to keep computed metrics
    dict_mean_proportions = {"Facies Type": facies_ids, "Real Data": real_mean_proportion, }
    dict_connected_sizes = {"Facies Type": facies_ids, "Real Data": real_conn_size, }
    dict_weighted_connected_sizes = {"Facies Type": facies_ids, "Real Data": real_weighted_conn_size, }

    for i, model in enumerate(models):
        print(models_names[i])
        # Generate some realisations using model, then compute morpho metrics
        random_noise = tf.random.normal(shape=(batch_size, *noise_shape))
        generated_samples = model(random_noise)

        if isinstance(generated_samples, list):
            # For multi_scales models
            generated_samples = generated_samples[-1]

        generated_samples = np.argmax(generated_samples, axis=-1).astype(np.float64)

        mean_proportion = compute_mean_facies_proportions(generated_samples, slice_size, batch_size, 2, unique_facies)
        _, ms_weighted_total_size, ms_total_size = get_connected_components_stats_per_facies(generated_samples, slice_size,
                                                                        batch_size, 2, unique_facies)
        dict_mean_proportions[models_names[i]] = mean_proportion
        dict_connected_sizes[models_names[i]] = ms_total_size
        dict_weighted_connected_sizes[models_names[i]] = ms_weighted_total_size

    # Plot Mean proportion (histogram)
    # print(dict_mean_proportions)
    df_mean_prop = pd.DataFrame(data=dict_mean_proportions)
    df_mean_prop = pd.melt(df_mean_prop, id_vars="Facies Type", var_name="Method", value_name="Mean Facies %")
    sns.set_style("whitegrid")
    sns.catplot(x='Facies Type', y='Mean Facies %', hue="Method", legend=False,
                data=df_mean_prop, kind='bar', alpha=.9,
                height=8, aspect=13.7 / 8.27)
    plt.legend(loc='upper right', title='Model')
    plt.show()

    # Plot Mean Connected components size (Violin plot, log scale)
    df_conct_size = pd.DataFrame(data=dict_weighted_connected_sizes)
    # print(df_conct_size)
    df_conct_size = pd.melt(df_conct_size, id_vars="Facies Type", var_name="Method",
                            value_name="Connected component size (nb of voxels in log scale)")
    df_conct_size = df_conct_size.explode("Connected component size (nb of voxels in log scale)")
    # to log scale otherwise it's unreadable
    df_conct_size["Connected component size (nb of voxels in log scale)"] = \
        np.log(df_conct_size["Connected component size (nb of voxels in log scale)"].astype('float64'))
    sns.set_style("whitegrid")

    g = sns.catplot(x='Facies Type', y='Connected component size (nb of voxels in log scale)', hue="Method",
                    data=df_conct_size, kind='violin', showfliers=True, legend=False,
                    height=8, aspect=13.7 / 8.27)

    # TEMPORARLY REMOVED THE WASSERSTEIN COMPUTATION BETWEEN MODELS DISTRIB OF CONNECTED COMPONENTS
    # array = [(2*i+1)*0.08 for i in range(len(models))]
    #models_names_tmp = ["Real Data"] + models_names
    #for i in range(len(facies_ids)):
    #    x_pos_text = (0.080 + i - 0.45)
    #    g.axes.flat[0].text(x_pos_text, -.35, 'Wassertein distance to real data', fontsize=9)
    #    for j in range(len(models) + 1):
            # y_pos_text = np.log(dict_connected_sizes[models_names_tmp[j]][i].max()) * 1.20

    #        y_pos_text = -.60
    #        x_pos_text = (5.5 * j + 2) * 0.080 + i - 0.45
    #        distance = scipy.stats.wasserstein_distance(dict_connected_sizes['Real Data'][i],
    #                                                    dict_connected_sizes[models_names_tmp[j]][i])

    #        g.axes.flat[0].text(x_pos_text, y_pos_text, '{:.2f}'.format(distance), fontsize=12)

    plt.legend(loc='upper right', title='Model')
    plt.show()

    return dict_mean_proportions, dict_connected_sizes


def compare_models_morpho(real_data, models, models_names, facies_ids=None, batch_size=750):
    """
    Compare models using morphological properties using gstlearn. Morphological properties are facies proportions
    and the distribution (violin plot) of connected components sizes.
    Args:
        real_data: (ndarray) The real dataset of images
        models: (list(keras.models.Model)) list of models coded in Tensorrflow/Keras
        models_names: (list(string)) a list of models names for the models (must be same size as array 'models')
        facies_ids: (list(string)) a list of facies IDs names
        batch_size: number of images generated by each models (there is no batch size for real data, morph. prop. will
                    be computed on the whole dataset)
    Returns:
        None
    """
    sns.set(font_scale=1.5)
    slice_size = (real_data.shape[1], real_data.shape[2])
    nb_facies = real_data.shape[-1]
    real_dataset_size = real_data.shape[0]

    # Array containing unique facies ID
    unique_facies = np.array(list(range(0, nb_facies)))

    if facies_ids is None:
        facies_ids = unique_facies

    # Compute it for real data
    real_data = np.argmax(real_data, axis=-1).astype(np.float64)
    real_mean_proportion = compute_mean_facies_proportions(real_data, slice_size, real_dataset_size, 2, unique_facies)
    _, real_weighted_conn_size, real_conn_size = get_connected_components_stats_per_facies(real_data, slice_size,
                                                                     real_dataset_size, 2, unique_facies)

    # Create the dictionaries to keep computed metrics
    dict_mean_proportions = {"Facies Type": facies_ids, "Real Data": real_mean_proportion, }
    dict_connected_sizes = {"Facies Type": facies_ids, "Real Data": real_conn_size, }
    dict_weighted_connected_sizes = {"Facies Type": facies_ids, "Real Data": real_weighted_conn_size, }

    for i, model in enumerate(models):
        print(models_names[i])
        # Generate some realisations using model, then compute morpho metrics
        random_noise = tf.Variable(generate_noise(batch_size, 8, 16, 1))
        generated_samples = model(random_noise)

        if isinstance(generated_samples, list):
            # For multi_scales models
            generated_samples = generated_samples[-1]

        generated_samples = np.argmax(generated_samples, axis=-1).astype(np.float64)

        mean_proportion = compute_mean_facies_proportions(generated_samples, slice_size, batch_size, 2, unique_facies)
        _, ms_weighted_total_size, ms_total_size = get_connected_components_stats_per_facies(generated_samples, slice_size,
                                                                        batch_size, 2, unique_facies)
        print(ms_total_size)
        dict_mean_proportions[models_names[i]] = mean_proportion
        dict_connected_sizes[models_names[i]] = ms_total_size
        dict_weighted_connected_sizes[models_names[i]] = ms_weighted_total_size

        del generated_samples

    # Plot Mean proportion (histogram)
    # print(dict_mean_proportions)
    df_mean_prop = pd.DataFrame(data=dict_mean_proportions)
    df_mean_prop = pd.melt(df_mean_prop, id_vars="Facies Type", var_name="Method", value_name="Mean Facies %")
    sns.set_style("whitegrid")
    sns.catplot(x='Facies Type', y='Mean Facies %', hue="Method", legend=False,
                data=df_mean_prop, kind='bar', alpha=.9,
                height=8, aspect=13.7 / 8.27)
    plt.legend(loc='upper right', title='Model')
    plt.show()

    # Plot Mean Connected components size (Violin plot, log scale)
    df_conct_size = pd.DataFrame(data=dict_weighted_connected_sizes)
    # print(df_conct_size)
    df_conct_size = pd.melt(df_conct_size, id_vars="Facies Type", var_name="Method",
                            value_name="Connected component size (nb of voxels in log scale)")
    df_conct_size = df_conct_size.explode("Connected component size (nb of voxels in log scale)")
    # to log scale otherwise it's unreadable
    df_conct_size["Connected component size (nb of voxels in log scale)"] = \
        np.log(df_conct_size["Connected component size (nb of voxels in log scale)"].astype('float64'))
    sns.set_style("whitegrid")

    g = sns.catplot(x='Facies Type', y='Connected component size (nb of voxels in log scale)', hue="Method",
                    data=df_conct_size, kind='violin', showfliers=True, legend=False,
                    height=8, aspect=13.7 / 8.27)

    # TEMPORARLY REMOVED THE WASSERSTEIN COMPUTATION BETWEEN MODELS DISTRIB OF CONNECTED COMPONENTS
    # array = [(2*i+1)*0.08 for i in range(len(models))]
    models_names_tmp = ["Real Data"] + models_names
    #for i in range(len(facies_ids)):
    #    x_pos_text = (0.080 + i - 0.45)
    #    g.axes.flat[0].text(x_pos_text, -.35, 'Wassertein distance to real data', fontsize=9)

    #    for j in range(len(models) + 1):
            # y_pos_text = np.log(dict_connected_sizes[models_names_tmp[j]][i].max()) * 1.20

    #        y_pos_text = -.60
    #        x_pos_text = (2 * j + 1) * 0.080 + i - 0.45
    #        distance = scipy.stats.wasserstein_distance(dict_connected_sizes['Real Data'][i],
    #                                                    dict_connected_sizes[models_names_tmp[j]][i])

     #       g.axes.flat[0].text(x_pos_text, y_pos_text, '{:.2f}'.format(distance), fontsize=9)

    plt.legend(loc='upper left', title='Model')
    plt.show()

    return dict_mean_proportions, dict_connected_sizes
